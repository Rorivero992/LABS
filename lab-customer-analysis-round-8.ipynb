{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d70f6450",
   "metadata": {},
   "source": [
    "### 01 - Problem (case study)\n",
    "\n",
    ".- El objetivo de estos datos es comprender la demografía de los clientes y el comportamiento de compra. Ademas se debe comprobar los clientes mas rentables y como interactuan. \n",
    "\n",
    ".- La descripción de datos se realiza acontinuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b00edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importamos todas las librerias necesarias.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy.stats import norm\n",
    "from scipy import stats \n",
    "from scipy.stats import skew\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "359ead72",
   "metadata": {},
   "source": [
    "### 02 - Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6e1efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importamos el CSV como un Dataframe llamado DF\n",
    "df=pd.read_csv(\"marketing_customer_analysis.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "104f4a40",
   "metadata": {},
   "source": [
    "### 03 - Cleaning/Wrangling/EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f621c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "#en este paso se tiene que hacer toda la limpieza del Data Frame, completar los Nan values, mirar los tipos de variables etc. \n",
    "#estandarizo los nombres de columnas y realizo una copia.\n",
    "\n",
    "df.columns=df.columns.str.upper().str.replace(' ','_')\n",
    "df1=df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629565ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hago la distinción de variables numericas y categoricas. \n",
    "\n",
    "numerical = df1.select_dtypes(include=np.number)\n",
    "categoricals = df1.select_dtypes(include=object)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f1873a3e",
   "metadata": {},
   "source": [
    "### 04 - Processing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf7a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo graficos de control para poder comprobar la distribución de mis variables. \n",
    "\n",
    "fig, axes = plt.subplots(len(numerical.columns), 1, figsize=(4, 2* len(numerical.columns)))\n",
    "\n",
    "for i, column in enumerate(numerical.columns):\n",
    "    sns.boxplot(numerical[column], ax=axes[i])\n",
    "    axes[i].set_title(column)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5380c1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES NUMERICAS. \n",
    "\n",
    "# Normalizo la variables numericas. \n",
    "transformer=StandardScaler().fit(numerical)\n",
    "x_normalized=transformer.transform(numerical)\n",
    "df_norm=pd.DataFrame(x_normalized)\n",
    "\n",
    "#Cambio nombres del Df normalizado y lo reemplazo por los nombres d elas columnas del DF numerico.\n",
    "col_num=numerical.columns\n",
    "df_norm.columns=col_num\n",
    "df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a51b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VARIABLES CATEGORICAS. \n",
    "\n",
    "#Elimino columnas que no tienen implicación en el analisis (aquellas columnas que tienen muchos elementos que se repiten solo una vez y no tienen relevancia para el modelo. al no eliminarlas, cuando se vaya a hacer el hot encoder, se generaran muchas columnas que alteraran el tamaño del dataframe). \n",
    "\n",
    "#Defino un nuevo DF sin esas columnas. \n",
    "\n",
    "df_categ=categoricals.drop(['EFFECTIVE_TO_DATE', 'CUSTOMER'],axis=1)\n",
    "df_categ\n",
    "\n",
    "#aplico el hot encoder a las variables numericas. \n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='error', drop='first')\n",
    "encoder.fit(df_categ)\n",
    "encoded = encoder.transform(df_categ).toarray()\n",
    "feature_names = encoder.get_feature_names_out(df_categ.columns)\n",
    "X_cat_encoded = pd.DataFrame(encoded, columns=feature_names)\n",
    "df_encod = df_categ.drop(df_categ.columns, axis=1)\n",
    "df_encod = pd.concat([df_encod, X_cat_encoded], axis=1)\n",
    "df_encod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "3b8e4af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#concateno ambos DF (categorico y numerico) ya trabajados. \n",
    "\n",
    "df_concat=pd.concat([df_norm, df_encod], axis=1 )\n",
    "df_concat=pd.DataFrame(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530b49f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo un train test con una muestra de 20%.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "Y=df_concat['TOTAL_CLAIM_AMOUNT']\n",
    "X=df_concat.drop(['TOTAL_CLAIM_AMOUNT'] , axis=1)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "lm=linear_model.LinearRegression()\n",
    "model=lm.fit(X_train, y_train)\n",
    "predictions=lm.predict(X_test)\n",
    "r2_score(y_test, predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68ac395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se transforma el resultado del Train test a Dataframe, solo para control. \n",
    "dfpred=pd.DataFrame(columns=[y_test, predictions]).T\n",
    "dfpred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5df1bca0",
   "metadata": {},
   "source": [
    "### 05 - Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f4d854",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo la 1ª regresión lineal, sobre el Df concatenado.\n",
    "Y=df_concat['TOTAL_CLAIM_AMOUNT']\n",
    "X=df_concat.drop(['TOTAL_CLAIM_AMOUNT'], axis=1)\n",
    "x=sm.add_constant(X)\n",
    "model=sm.OLS(Y,X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4f85db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Al encontrarme con variables con un P valor alto, pruebo eliminarlas, para ver si el modelo mejora.\n",
    "df2_concat=df_concat.copy()\n",
    "df2_concat=df_concat.drop(['MONTHS_SINCE_POLICY_INCEPTION'] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3368ff07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Realizo una 2ª regresion lineal sin la columna MONTHS_SINCE_POLICY_INCEPTION \n",
    "Y=df2_concat['TOTAL_CLAIM_AMOUNT']\n",
    "X=df2_concat.drop(['TOTAL_CLAIM_AMOUNT'], axis=1)\n",
    "x=sm.add_constant(X)\n",
    "model=sm.OLS(Y,X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3ac6e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#al ver que la regresion lineal no ha cambiado quitando 1 columna, mirare las que tengan mas P valor. \n",
    "\n",
    "Y = df_concat['TOTAL_CLAIM_AMOUNT']\n",
    "X = df_concat.drop(['TOTAL_CLAIM_AMOUNT'], axis=1)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "\n",
    "# Filtrar variables con el p-valor más alto (por ejemplo, umbral de 0.05)\n",
    "\n",
    "significant_variables = model.pvalues[model.pvalues > 0.05]\n",
    "significant_variables_sorted = significant_variables.sort_values(ascending=False)\n",
    "significant_variables_sorted\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aaf1537",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hago una ultima prueba, quitaré las columnas con variables con P valor alta y que no sean relevantes para el modelo.\n",
    "df3_concat=df2_concat.copy()\n",
    "df3_concat=df2_concat.drop(['VEHICLE_CLASS_Two-Door Car', 'VEHICLE_CLASS_Luxury SUV', 'POLICY_Corporate L3', 'VEHICLE_SIZE_Small', 'SALES_CHANNEL_Web', 'POLICY_TYPE_Personal Auto', 'EMPLOYMENTSTATUS_Retired', 'POLICY_Corporate L2', 'SALES_CHANNEL_Branch', ] , axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7892cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ralizo una 3ª regresion lineal despues de haber eliminado unas cuantas columnas. \n",
    "\n",
    "Y = df3_concat['TOTAL_CLAIM_AMOUNT']\n",
    "X = df3_concat.drop(['TOTAL_CLAIM_AMOUNT'], axis=1)\n",
    "X = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X).fit()\n",
    "print(model.summary())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "228ba795",
   "metadata": {},
   "source": [
    "### 06 - Model Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e675ab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#varianza\n",
    "mse=mean_squared_error(y_test, predictions) \n",
    "print(\"MSE es =\" , mse)\n",
    "\n",
    "#error estándar\n",
    "rmse= math.sqrt(mse) \n",
    "print(\"RMSE es =\", rmse)\n",
    "\n",
    "# valores de 0 a 1, cuanto más cercano a 1 mejor. \n",
    "r2=r2_score(y_test, predictions) \n",
    "print(\"R2 es =\", r2)\n",
    "\n",
    "#igual que r2 pero penaliza el incluir variables independientes que no aporten al modelo.\n",
    "n=len(X_test)  \n",
    "p=X_test.shape[1]\n",
    "adj_r2=1-((1-r2)*(n-1)/(n-p-1))\n",
    "print(\"R2 AJUSTADO es =\", adj_r2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02c02232",
   "metadata": {},
   "source": [
    "### 07 - Reporting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c991ad9",
   "metadata": {},
   "source": [
    "Informe de Regresión Lineal\n",
    "\n",
    "se analizó un modelo de regresión lineal para predecir el \"TOTAL CLAIM AMOUNT\" (Monto total de reclamaciones). \n",
    "\n",
    "El modelo resultante mostró un coeficiente de determinación (R2) de 0.761, lo que indica que aproximadamente el 76.1% de la variabilidad en el monto total de reclamaciones se explica por las variables independientes incluidas en el modelo. Además, el valor ajustado del R2 fue de 0.760, lo que sugiere que el modelo también se ajusta adecuadamente a nuevos datos.\n",
    "\n",
    "El análisis de los coeficientes estimados reveló las siguientes relaciones significativas con el \"TOTAL CLAIM AMOUNT\":\n",
    "\n",
    "La variable \"MONTHLY PREMIUM AUTO\" mostró un coeficiente positivo de 0.8318, aqui se podria inferir que hay una vinculación entre el tipo de poliza y el monto de las reclamaciones.\n",
    "\n",
    "Las variables \"STATE_California\", \"STATE_Nevada\", \"STATE_Oregon\" y \"STATE_Washington\" mostraron coeficientes negativos, lo que sugiere una relación inversa entre variables. \n",
    "\n",
    "El análisis de los p-valores reveló muchas de las variables del modelo tenian un valor superior a 0.05.\n",
    "\n",
    "Con la ultima (3ª) regresión, se puede comprobar que al eliminar varias columnas con P valor alto (no todas) el R2 y el R2 ajustado han aumentado, por lo que se puede concluir que el modelo esta mas ajustado a la realidad. De igual forma la primera regresión tenía un R2 de 0,761, el cual es un resultado \"aceptable\". Otro aspecto a tener en cuenta, es que hay un problema de multicolinealidad, lo que podria llegar a dificultar las interpretaciones del modelo. No es conveniente eliminar todas las variables que consideremos no utiles, ya que se debe encontrar un equilibrio entre reducir la multicolinealidad y mantener la capacidad explicativa del modelo.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
